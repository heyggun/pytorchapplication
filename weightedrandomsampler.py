# -*- coding: utf-8 -*-
"""weightedrandomsampler.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qSbKv6qLmT8QvyvBpm_xNyBokwA5SS_V
"""

import torch
import torchvision.datasets as datasets
import os
from torch.utils.data import WeightedRandomSampler, DataLoader
import torchvision.transforms as transforms
import torch.nn as nn

# Methods for dealing with imbalanced datasets
# 1. Oversampling
# 2. Class weighting

# loss에 대한 weight를 달리 주는 방법(class weighting)
loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([1, 50]))

# -------------------------------------------------------

# Oversampling via class weighting

def get_loader(root_dir, batch_size):
  my_transforms = transforms.Compose(
      [
       transforms.Resize((10, 10)),
       transforms.ToTensor(),
      ]
  )
  
  dataset = datasets.ImageFolder(root=root_dir, transform=my_transforms)
  class_weights = []

  for root, subdir, files in os.walk(root_dir):
    if len(files) > 0:
      class_weights.append(1/len(files))

  sample_weights = [0] * len(dataset)

  for idx, (data, label) in enumerate(dataset):
    class_weight = class_weights[label-1]
    sample_weights[idx] = class_weight

  sampler = WeightedRandomSampler(sample_weights, num_samples=
                                  len(sample_weights), replacement=True)
  loader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)
  return loader

def main():
  loader = get_loader(root_dir="dataset", batch_size = 8)

  num_majority = 0
  num_minority = 0

  for epoch in range(10):
    for data, labels in loader:
      num_majority += torch.sum(labels==1)
      num_minority += torch.sum(labels==2)
    
  print(num_majority, num_minority)

if __name__ == "__main__":
  main()

